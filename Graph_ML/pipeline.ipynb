{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import xgi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "embeddings = pd.read_csv('full_users_embeddings.csv')\n",
    "embeddings = embeddings.iloc[:, np.r_[0:3, -768:0]]\n",
    "embeddings['one_hot'] = 0\n",
    "\n",
    "print('embeddings shape: ', embeddings.shape)\n",
    "\n",
    "df = pd.read_json('babynamesDB_users.json')\n",
    "hyperedge_list = df[['_id', 'groups']]\n",
    "\n",
    "print('hyperedge list shape: ', hyperedge_list.shape)\n",
    "\n",
    "# only keep users that are in the embeddings dataframe\n",
    "hyperedge_list_copy = hyperedge_list.copy()\n",
    "hyperedge_list_copy = hyperedge_list_copy[hyperedge_list_copy['_id'].isin(embeddings['_id'].values)]\n",
    "hyperedge_list_copy['_id'] = hyperedge_list_copy.index.astype(int)\n",
    "\n",
    "hyperedge_list_copy = hyperedge_list_copy.explode('groups')\n",
    "# turn groups to one hot encoding\n",
    "hyperedge_list_copy['groups'] = hyperedge_list_copy['groups'].astype('category')\n",
    "\n",
    "hyperedge_list_copy['groups'] = hyperedge_list_copy['groups'].cat.codes.astype(int)\n",
    "\n",
    "H = xgi.from_bipartite_pandas_dataframe(hyperedge_list_copy)\n",
    "\n",
    "print('Hypergraph loaded')\n",
    "\n",
    "G = xgi.to_bipartite_graph(H)\n",
    "\n",
    "num_groups = H.num_edges\n",
    "num_embeddings = embeddings.shape[1]\n",
    "column_names = embeddings.columns\n",
    "new_rows = []\n",
    "for i in range(1, num_groups + 1):\n",
    "    #create a new row for each group\n",
    "    new_row = pd.DataFrame(np.zeros((1, num_embeddings)), columns = column_names)\n",
    "    new_row['one_hot'] = i\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "embeddings = pd.concat([embeddings] + new_rows, ignore_index=True)\n",
    "embeddings = embeddings.iloc[:-14, :]\n",
    "\n",
    "print('Embeddings dataframe augmented: ')\n",
    "\n",
    "# loop through each row in embeddings and set the corresponding feature of that node in the graph to the embedding\n",
    "attrs = {}\n",
    "for i in range(embeddings.shape[0]):\n",
    "    # every column except the first three is an embedding\n",
    "    attr = embeddings.iloc[i, 3:-1].to_dict()\n",
    "    attrs[i] = attr\n",
    "\n",
    "print('setting node attributes')\n",
    "    \n",
    "nx.set_node_attributes(G, attrs)\n",
    "\n",
    "print('node attributes set')\n",
    "\n",
    "pyg_graph = from_networkx(G)\n",
    "\n",
    "print('graph converted to pytorch geometric graph')\n",
    "\n",
    "data = train_test_split_edges(pyg_graph)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_groups, num_layers, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(input_dim, hidden_dim)])\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.convs.append(GCNConv(hidden_dim, num_groups))  # Output layer for group prediction\n",
    "\n",
    "        # Batch normalization layers\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x_hat = x\n",
    "        for i in range(len(self.convs)-1):\n",
    "            x_hat = self.convs[i](x_hat, edge_index)\n",
    "            x_hat = self.bns[i](x_hat)\n",
    "            x_hat = F.relu(x_hat)\n",
    "            x_hat = F.dropout(x_hat, self.dropout, training=self.training)\n",
    "        return self.convs[-1](x_hat, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.train_pos_edge_index)\n",
    "        link_logits = self.decode(z, data.train_pos_edge_index)\n",
    "        return link_logits\n",
    "\n",
    "def train(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    link_logits = model(data)\n",
    "    link_labels = torch.cat([torch.ones(data.train_pos_edge_index.size(1)), \n",
    "                             torch.zeros(data.train_neg_edge_index.size(1))], dim=0)\n",
    "    loss = loss_fn(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    pos_link_logits = model.encode(data.x, data.test_pos_edge_index)\n",
    "    neg_link_logits = model.encode(data.x, data.test_neg_edge_index)\n",
    "    pos_link_probs = F.softmax(pos_link_logits, dim=1)\n",
    "    neg_link_probs = F.softmax(neg_link_logits, dim=1)\n",
    "    # Here you can calculate the evaluation metrics like AUC, Accuracy, etc.\n",
    "    return pos_link_probs, neg_link_probs\n",
    "\n",
    "input_dim = embeddings.shape[1] - 4  # Minus 4 to exclude '_id', 'one_hot', and two additional columns\n",
    "hidden_dim = 64  # Example value, you may need to tune this\n",
    "num_groups = hyperedge_list['groups'].nunique()  # Assuming this is the number of groups\n",
    "num_layers = 2   # Number of layers in GCN\n",
    "dropout = 0.5    # Dropout rate\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, num_groups, num_layers, dropout)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Learning rate may need tuning\n",
    "num_epochs = 100  # Number of epochs to train\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, data, optimizer, loss_fn)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{num_epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "pos_link_probs, neg_link_probs = test(model, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
